{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from bleu_eval import BLEU\n",
    "import re\n",
    "from tensorboardX import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def process_text(s):\n",
    "    s = re.sub(r'\\s\\'\\s', \"'\", s)\n",
    "    s = re.sub(r'\\s([\\.\\!\\?\\,])', r\"\\1\", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'eng-fra.txt', 'test_text.csv', 'train_text.csv']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir('./data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build word dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/eng-fra.txt', 'r', encoding='utf-8') as f:\n",
    "#     s = f.readline()\n",
    "\n",
    "# text = pd.read_csv('data/eng-fra.txt', header=None, names=['eng', 'fra'], encoding='utf-8', sep='\\t')[:12000]\n",
    "# index = np.arange(text.shape[0])\n",
    "# np.random.shuffle(index)\n",
    "# text2 = text.loc[index[10000:12000]]\n",
    "# text = text.loc[index[:10000]]\n",
    "# text.to_csv('data/train_text.csv', index=False, encoding='utf-8', sep='\\t')\n",
    "# text2.to_csv('data/test_text.csv', index=False, encoding='utf-8', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = pd.read_csv('data/train_text.csv', encoding='utf-8', sep='\\t')\n",
    "text2 = pd.read_csv('data/test_text.csv', encoding='utf-8', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2) (2000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(text1.shape, text2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 2)\n"
     ]
    }
   ],
   "source": [
    "text = pd.concat([text1, text2], axis=0)\n",
    "print(text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern=\"\\\\b\\\\w+\\\\b|!|\\\\?|\\\\'|\\\\.\",\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv1 = CountVectorizer(min_df=3,token_pattern=r\"\\b\\w+\\b|!|\\?|\\'|\\.\")\n",
    "cv2 = CountVectorizer(min_df=5,token_pattern=r\"\\b\\w+\\b|!|\\?|\\'|\\.\")\n",
    "cv1.fit(text.eng)\n",
    "cv2.fit(text.fra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_word_dict(cv):\n",
    "    num_word = len(cv.get_feature_names())\n",
    "    word_index = {k:v+1 for k,v in cv.vocabulary_.items()}  # 1~num_word vaild index\n",
    "    word_index['<bos>'] = num_word+1\n",
    "    word_index['<eos>'] = num_word+2\n",
    "    index_word = dict(zip(word_index.values(), word_index.keys()))\n",
    "    return num_word+3, word_index, index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1205 914\n"
     ]
    }
   ],
   "source": [
    "num_word_eng, word_index_eng, index_word_eng = build_word_dict(cv1)\n",
    "num_word_fra, word_index_fra, index_word_fra = build_word_dict(cv2)\n",
    "print(num_word_eng, num_word_fra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1204"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2int(word_index, texts, add_xos=False):\n",
    "    tokenizer = CountVectorizer(token_pattern=r\"\\b\\w+\\b|!|\\?|\\'|\\.\").build_tokenizer()\n",
    "#     return [[word_index.get(j, 0)+1 for j in tokenizer(i.lower())] for i in texts]\n",
    "    res = []\n",
    "    bos, eos = [word_index.get('<bos>')], [word_index.get('<eos>')]\n",
    "    for t in texts:\n",
    "        if add_xos:\n",
    "            res.append(bos + [word_index.get(i, 0) for i in tokenizer(t.lower())] + eos)\n",
    "        else:\n",
    "            res.append([word_index.get(i, 0) for i in tokenizer(t.lower())])\n",
    "    return res\n",
    "\n",
    "def int2text(index_word, intcode):\n",
    "    return [' '.join([index_word.get(j, '<null>') for j in i] ) for i in intcode]\n",
    "\n",
    "def word_count(cv, texts):\n",
    "    trans = cv.transform(texts)\n",
    "    wc = trans.sum(axis=0)\n",
    "    wc = np.asarray(wc).squeeze()\n",
    "    return {k:v for k, v in zip(cv.get_feature_names(), wc)}\n",
    "\n",
    "def padding(s, pad=0):\n",
    "    max_len = max(map(len, s))\n",
    "    res = []\n",
    "    for ss in s:\n",
    "        t = [0]*max_len\n",
    "        t[max_len-len(ss):]=ss\n",
    "        res.append(t)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EncoderRNN & DecoderRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size, padding_idx=0)\n",
    "        self.gru = nn.GRU(input_size=hidden_size, hidden_size=hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        x = self.embedding(input)  # input: (seq_len, batch_size)\n",
    "        out, h_n = self.gru(x, hidden)  # input: (seq_len, batch_size, embedding_dim)\n",
    "        return out, h_n\n",
    "\n",
    "    def initHidden(self, batch_size=1):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, device=device)\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size, padding_idx=0)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        x = self.embedding(input)  # input: (seq_len=1, batch_size)\n",
    "#         x = F.relu(x)  # input: (seq_len=1, batch_size, embedding_dim)\n",
    "        output, h_1 = self.gru(x, hidden)\n",
    "#         out = F.softmax(self.out(output[0]), dim=1)  # out: (batch_size, hidden_size)\n",
    "        out = self.softmax(self.out(output[0]))  # output[0]: (batch_size, hidden_size)\n",
    "        return out, h_1  # hidden: (1, batch_size, hidden_size)\n",
    "\n",
    "    def initHidden(self, batch_size=1):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AttnDecoderRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention 实现方式 1：decoder hidden vector 与 输入做 attention 产生权重\n",
    "\n",
    "<img src=\"mt-atten.png\" width=\"350px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=10):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):  # input: (1, b), hidden: (1, b, h), encoder_outputs: (s, b, h)\n",
    "        embedded = self.embedding(input)  # embedded: (1, b, h)\n",
    "#         embedded = self.dropout(embedded)\n",
    "#         print(embedded.shape)\n",
    "#         print(embedded[0].shape, hidden[0].shape)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)  # attn_weights: (b, l)\n",
    "#         print(attn_weights.shape)\n",
    "        \n",
    "        encoder_outputs_len = encoder_outputs.shape[0]\n",
    "        e_out = torch.zeros(self.max_length, encoder_outputs.shape[1], encoder_outputs.shape[2], device=device)\n",
    "        for i in range(min(encoder_outputs_len, self.max_length)):\n",
    "#             e_out[-i-1] = encoder_outputs[-i-1]\n",
    "            e_out[i] = encoder_outputs[i]\n",
    "        temp1 = e_out.permute(1, 2, 0)  # (b, h, l)\n",
    "        temp2 = attn_weights.unsqueeze(2)  # (b, l, 1)\n",
    "#         print(temp1.shape, temp2.shape)\n",
    "        \n",
    "        attn_applied = torch.bmm(temp1, temp2).permute(2, 0, 1)  # (1, b, h)\n",
    "#         print(attn_applied.shape)\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)  # (b, 2*h)\n",
    "        output = self.attn_combine(output).unsqueeze(0)  # (1, b, h)\n",
    "\n",
    "#         output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)  # (b, d)\n",
    "#         print(output.shape)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AttnDecoderRNN_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention 实现方式 2：decoder hidden vector 与 encoder outputs 做 attention 产生权重\n",
    "\n",
    "<img src=\"mt-atten2.jpg\" width=\"550px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN_2(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=10):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size, padding_idx=0)\n",
    "#         self.attn1 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "#         self.attn2 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "#         self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):  # input: (1, b), hidden: (1, b, h), encoder_outputs: (s, b, h)\n",
    "        emb = self.embedding(input)  # shape: (1, b, h)\n",
    "        \n",
    "        encoder_outputs_len = encoder_outputs.shape[0]\n",
    "        e_out = torch.zeros(self.max_length, encoder_outputs.shape[1], encoder_outputs.shape[2], device=device)\n",
    "        for i in range(min(encoder_outputs_len, self.max_length)):\n",
    "#             e_out[-i-1] = encoder_outputs[-i-1]\n",
    "            e_out[i] = encoder_outputs[i]\n",
    "        temp1 = e_out.permute(1,0,2)  # (b, l, h)\n",
    "        temp2 = hidden.permute(1,2,0)  # (b, h, 1)\n",
    "#         print(temp1.device, temp2.device)\n",
    "        attn_weights = F.softmax(torch.bmm(temp1, temp2).squeeze(2), dim=1)  # (b, l)\n",
    "        attn_applied = torch.bmm(e_out.permute(1, 2, 0), attn_weights.unsqueeze(2)).permute(2, 0, 1)  # (1, b, h)\n",
    "        \n",
    "        x = torch.cat((emb, attn_applied), dim=2)  # (1, b, 2*h)\n",
    "        x = self.attn_combine(x)  # (1, b, h)\n",
    "        out, hidden, = self.gru(x, hidden)\n",
    "        output = F.log_softmax(self.out(out[0]), dim=1)  # (b, d)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = 3\n",
    "# h = 8\n",
    "# s = 11\n",
    "# l = 10\n",
    "# d = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ade = AttnDecoderRNN_2(h, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x0 = torch.ones(1, b, dtype=torch.long)\n",
    "# h0 = torch.zeros(1, b, h)\n",
    "# e_out = torch.ones(s, b, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_out = ade(x0, h0, e_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_out[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttenEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, latent_dim):\n",
    "        super().__init__()\n",
    "#         self.input_len = input_len\n",
    "#         self.latent_dim = latent_dim\n",
    "        self.Embedding = nn.Embedding(input_size, latent_dim, padding_idx=0)\n",
    "#         self.T = nn.Linear(latent_dim, latent_dim)\n",
    "        self.Wq = nn.Linear(latent_dim, latent_dim)\n",
    "        self.Wk = nn.Linear(latent_dim, latent_dim)\n",
    "        self.Wv = nn.Linear(latent_dim, latent_dim)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = self.Embedding(input)  # (s, b) -> (s, b, h)\n",
    "#         x = F.relu(self.T(x))\n",
    "        q = self.Wq(x)  # (s, b, h) -> (s, b, h)\n",
    "        k = self.Wq(x)  # (s, b, h) -> (s, b, h)\n",
    "        v = self.Wq(x)  # (s, b, h) -> (s, b, h)\n",
    "        a = F.softmax(torch.bmm(q.permute(1,0,2), k.permute(1,2,0)), dim=1)  # (b, s, s)\n",
    "        out = torch.bmm(a, v.permute(1,0,2)).permute(1,0,2)  # (s, b, h)\n",
    "        out_mean = out.mean(dim=0)  # (b, h)\n",
    "        return out, out_mean, a\n",
    "\n",
    "    \n",
    "class SelfAttenDecoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, output_size, latent_dim, max_len=9):\n",
    "        super().__init__()\n",
    "        self.max_len = max_len\n",
    "        self.Wq = nn.Linear(latent_dim, latent_dim)\n",
    "        self.Wk = nn.Linear(latent_dim, latent_dim)\n",
    "        self.Wv = nn.Linear(latent_dim, latent_dim)\n",
    "        self.out = nn.Linear(latent_dim, output_size)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = torch.zeros(self.max_len, input.shape[1], input.shape[2], device=device)\n",
    "        for i in range(min(self.max_len, input.shape[0])):\n",
    "            x[i] = input[i]\n",
    "        q = self.Wq(x)  # (s, b, h) -> (s, b, h)\n",
    "        k = self.Wq(x)  # (s, b, h) -> (s, b, h)\n",
    "        v = self.Wq(x)  # (s, b, h) -> (s, b, h)\n",
    "        a = F.softmax(torch.bmm(q.permute(1,0,2), k.permute(1,2,0)), dim=1)  # (b, s, s)\n",
    "        out = torch.bmm(a, v.permute(1,0,2)).permute(1,0,2)  # (s, b, h)\n",
    "        out = F.log_softmax(self.out(out), dim=2)  # (s, b, d)\n",
    "        return out, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 3\n",
    "h = 8\n",
    "s = 6\n",
    "l = 10\n",
    "d = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selfatten = SelfAttenEncoder(d, h)\n",
    "# sad = SelfAttenDecoder(d, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 3, 8])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x = torch.randint(d, (s, b), dtype=torch.long)\n",
    "x = torch.rand(s, b, h)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = sad(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y.shape\n",
    "# y[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(d,h,bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(s, b, d)\n",
    "h0 = torch.zeros(2, b, h)\n",
    "c0 = torch.zeros(2, b, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = lstm(x, (h0,c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 8])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datagen:\n",
    "    \n",
    "    def __init__(self, text_table, batch_size=5, shuffle=True):\n",
    "        super().__init__()\n",
    "        self.text_table = text_table\n",
    "        self.batch_size = batch_size\n",
    "        self.num_samples = text_table.shape[0]\n",
    "        self.shuffle = shuffle\n",
    "        self._index = np.arange(self.num_samples)\n",
    "        if shuffle:\n",
    "            np.random.shuffle(self._index)\n",
    "        mod = self.num_samples % batch_size\n",
    "        if mod > 0:\n",
    "            self._index = np.hstack([self._index, np.random.choice(self._index, self.batch_size-mod)])\n",
    "        self._idx_bat = [self._index[i:i+self.batch_size] for i in range(0, self.num_samples, self.batch_size)] \n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.num_samples/self.batch_size))\n",
    "    \n",
    "    def shuffle_data(self):\n",
    "        np.random.shuffle(self._index)\n",
    "        self._idx_bat = [self._index[i:i+self.batch_size] for i in range(0, self.num_samples, self.batch_size)] \n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        idx = self._idx_bat[i]\n",
    "        input_text = self.text_table.iloc[idx, 1].tolist()\n",
    "        target_text = self.text_table.iloc[idx, 0].tolist()\n",
    "        x = text2int(word_index_fra, input_text)\n",
    "        x = padding(x)\n",
    "        y = text2int(word_index_eng, target_text, add_xos=True)\n",
    "        y = padding(y)\n",
    "        x = torch.tensor(x, dtype=torch.long).permute(1,0)\n",
    "        y = torch.tensor(y, dtype=torch.long).permute(1,0)\n",
    "        return x, y[:-1,:], y[1:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train RNN encoder-decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "latent_dim = 256\n",
    "learning_rate = .002\n",
    "epochs = 20\n",
    "start_epoch = 1\n",
    "\n",
    "teacher_forcing_rate = 1\n",
    "write_log = False\n",
    "change_lr = False\n",
    "\n",
    "\n",
    "def predict(encoder, decoder, input_text, max_len=10):\n",
    "    with torch.no_grad():\n",
    "        input_code = text2int(word_index_fra, [input_text])\n",
    "        input_tensor = torch.tensor(input_code, dtype=torch.long).permute(1,0).to(device)\n",
    "        _, context_vector = encoder(input_tensor, encoder.initHidden(1))\n",
    "    #     print(context_vector)\n",
    "        bos_tensor = torch.tensor(word_index_eng['<bos>'], dtype=torch.long).view(1,1).to(device)\n",
    "        decoder_out, decoder_state = decoder(bos_tensor, context_vector)\n",
    "    #     print(decoder_out.sum())\n",
    "        pred_int = decoder_out.argmax().item()\n",
    "        input_tensor = decoder_out.argmax().view(1,1)\n",
    "    #     print(input_tensor)\n",
    "    #     print(pred_int)\n",
    "        res = []\n",
    "        count = 0\n",
    "        while pred_int!=word_index_eng['<eos>'] and count<max_len:\n",
    "            res.append(pred_int)\n",
    "            decoder_out, decoder_state = decoder(input_tensor, decoder_state)\n",
    "            pred_int = decoder_out.argmax().item()\n",
    "            input_tensor = decoder_out.argmax().view(1,1)\n",
    "            count += 1\n",
    "    return int2text(index_word_eng, [res])[0]\n",
    "\n",
    "\n",
    "def evel_bleu(test_pair, encoder, decoder):\n",
    "    res = []\n",
    "    for i in range(test_pair.shape[0]):\n",
    "        pred = predict(encoder, decoder, test_pair.iloc[i, 1])\n",
    "        pred = process_text(pred)\n",
    "        res.append(BLEU(pred, test_pair.iloc[i, 0]))\n",
    "    return np.mean(res)\n",
    "\n",
    "\n",
    "def calc_acc(true, pred):\n",
    "    with torch.no_grad():\n",
    "        acc = torch.eq(true, pred).float().mean().item()\n",
    "    return acc\n",
    "    \n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    if epoch < 2:\n",
    "        lr = .002\n",
    "    elif epoch < 7:\n",
    "        lr = .001\n",
    "    elif epoch < 12:\n",
    "        lr = .0005\n",
    "    elif epoch < 16:\n",
    "        lr = .0002  # .0002\n",
    "    else:\n",
    "        lr = .0001  # .0001\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "dataset = Datagen(text1, batch_size=batch_size, shuffle=False)\n",
    "num_iter_one_epoch = len(dataset)\n",
    "print(num_iter_one_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder = EncoderRNN(num_word_fra, latent_dim).to(device)\n",
    "decoder = DecoderRNN(latent_dim, num_word_eng).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "loss_fun = nn.NLLLoss()\n",
    "# loss_fun = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5000/5000  loss: 1.339 - acc: 0.833\n",
      "train_bleu: 0.4249830833937208 - test_bleu: 0.357\n",
      "Epoch 2/20\n",
      "5000/5000  loss: 1.533 - acc: 0.750\n",
      "train_bleu: 0.5091463773178746 - test_bleu: 0.403\n",
      "Epoch 3/20\n",
      "5000/5000  loss: 0.270 - acc: 1.000\n",
      "train_bleu: 0.6770244914829243 - test_bleu: 0.494\n",
      "Epoch 4/20\n",
      "5000/5000  loss: 0.372 - acc: 0.900\n",
      "train_bleu: 0.7097078597756856 - test_bleu: 0.508\n",
      "Epoch 5/20\n",
      "5000/5000  loss: 0.858 - acc: 0.833\n",
      "train_bleu: 0.7303130907978316 - test_bleu: 0.510\n",
      "Epoch 6/20\n",
      "5000/5000  loss: 0.471 - acc: 0.900\n",
      "train_bleu: 0.7431641681128058 - test_bleu: 0.518\n",
      "Epoch 7/20\n",
      "5000/5000  loss: 0.644 - acc: 0.833\n",
      "train_bleu: 0.751857379497905 - test_bleu: 0.521\n",
      "Epoch 8/20\n",
      "5000/5000  loss: 0.448 - acc: 0.800\n",
      "train_bleu: 0.7771868047490272 - test_bleu: 0.533\n",
      "Epoch 9/20\n",
      "5000/5000  loss: 0.217 - acc: 0.857\n",
      "train_bleu: 0.7861927242723102 - test_bleu: 0.537\n",
      "Epoch 10/20\n",
      "5000/5000  loss: 0.077 - acc: 1.000\n",
      "train_bleu: 0.7910976885541476 - test_bleu: 0.533\n",
      "Epoch 11/20\n",
      "5000/5000  loss: 0.246 - acc: 0.857\n",
      "train_bleu: 0.7822344919639793 - test_bleu: 0.533\n",
      "Epoch 12/20\n",
      "5000/5000  loss: 0.086 - acc: 1.000\n",
      "train_bleu: 0.7900761954544048 - test_bleu: 0.541\n",
      "Epoch 13/20\n",
      "5000/5000  loss: 0.299 - acc: 0.833\n",
      "train_bleu: 0.7922127941175945 - test_bleu: 0.536\n",
      "Epoch 14/20\n",
      "5000/5000  loss: 0.021 - acc: 1.000\n",
      "train_bleu: 0.7968270109306176 - test_bleu: 0.541\n",
      "Epoch 15/20\n",
      "5000/5000  loss: 0.423 - acc: 0.700\n",
      "train_bleu: 0.7926435752666382 - test_bleu: 0.539\n",
      "Epoch 16/20\n",
      "5000/5000  loss: 0.251 - acc: 0.929\n",
      "train_bleu: 0.7950550368612324 - test_bleu: 0.538\n",
      "Epoch 17/20\n",
      "5000/5000  loss: 0.135 - acc: 0.929\n",
      "train_bleu: 0.7921263984885442 - test_bleu: 0.535\n",
      "Epoch 18/20\n",
      "5000/5000  loss: 0.010 - acc: 1.000\n",
      "train_bleu: 0.7904472830298754 - test_bleu: 0.536\n",
      "Epoch 19/20\n",
      "5000/5000  loss: 0.184 - acc: 0.857\n",
      "train_bleu: 0.7980632348384727 - test_bleu: 0.539\n",
      "Epoch 20/20\n",
      "5000/5000  loss: 0.117 - acc: 1.000\n",
      "train_bleu: 0.7960808540499477 - test_bleu: 0.538\n"
     ]
    }
   ],
   "source": [
    "if write_log:\n",
    "    writer = SummaryWriter(log_dir='logdir')\n",
    "\n",
    "encoder_init_state = encoder.initHidden(batch_size)\n",
    "# decoder_init_state = decoder.initHidden(batch_size)\n",
    "for i in range(start_epoch, epochs+start_epoch):\n",
    "    print('Epoch {}/{}'.format(i, epochs+start_epoch-1))\n",
    "    dataset.shuffle_data()\n",
    "    \n",
    "    if change_lr:\n",
    "        adjust_learning_rate(encoder_optimizer, i)\n",
    "        adjust_learning_rate(decoder_optimizer, i)\n",
    "    \n",
    "    epoch_acc = []\n",
    "    epoch_loss = []\n",
    "    for j in range(0, num_iter_one_epoch):\n",
    "        x, y1, y2 = dataset[j]  # x, y1, y2 shape: (seq_len, batch_size)\n",
    "        x = x.to(device)\n",
    "        y1 = y1.to(device)\n",
    "        y2 = y2.to(device)\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        _, context_vector = encoder(x, encoder_init_state)\n",
    "        decoder_state = context_vector\n",
    "        decoder_out = []\n",
    "        decoder_input = y1[0].view(1,-1)\n",
    "        for k in range(y1.shape[0]):    \n",
    "            out, decoder_state = decoder(decoder_input, decoder_state)  # out shape: (batch_size, class)\n",
    "            try:\n",
    "                decoder_input = y1[k + 1].view(1, -1) if np.random.rand() < teacher_forcing_rate \\\n",
    "                        else out.argmax(dim=1).view(1, -1).detach()\n",
    "            except:\n",
    "                pass\n",
    "            decoder_out.append(out)\n",
    "        decoder_outputs = torch.stack(decoder_out)\n",
    "        decoder_outputs_int = torch.argmax(decoder_outputs, dim=2)\n",
    "        acc = calc_acc(y2.view(-1), decoder_outputs_int.view(-1))\n",
    "        loss = loss_fun(decoder_outputs.view(-1, num_word_eng), y2.view(-1))\n",
    "        print('{}/{}  loss: {:.3f} - acc: {:.3f}'.format(j+1, num_iter_one_epoch, loss.item(), acc), end='\\r')\n",
    "        \n",
    "        epoch_acc.append(acc)\n",
    "        epoch_loss.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        \n",
    "        if write_log:\n",
    "            writer.add_scalar('loss', loss, (i-1)*num_iter_one_epoch+j+1)\n",
    "            writer.add_scalar('acc', acc, (i-1)*num_iter_one_epoch+j+1)\n",
    "        \n",
    "    test_bleu = evel_bleu(text2, encoder, decoder)\n",
    "    train_bleu = evel_bleu(text1[:2000], encoder, decoder)\n",
    "    print('\\nloss: {:.3f} - acc: {:.3f} - train_bleu: {:.3f} - test_bleu: {:.3f}'\\\n",
    "          .format(np.mean(epoch_loss), np.mean(epoch_acc), train_bleu, test_bleu))\n",
    "    \n",
    "    if write_log:\n",
    "        writer.add_scalar('test_bleu', test_bleu, i*num_iter_one_epoch)\n",
    "        writer.add_scalar('train_bleu', train_bleu, i*num_iter_one_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), './model/encoder.mdl')\n",
    "torch.save(decoder.state_dict(), './model/decoder.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['embedding.weight', 'gru.weight_ih_l0', 'gru.weight_hh_l0', 'gru.bias_ih_l0', 'gru.bias_hh_l0'])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecoderRNN(\n",
      "  (embedding): Embedding(1205, 256, padding_idx=0)\n",
      "  (gru): GRU(256, 256)\n",
      "  (out): Linear(in_features=256, out_features=1205, bias=True)\n",
      "  (softmax): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "latent_dim = 256\n",
    "learning_rate = .001\n",
    "epochs = 1\n",
    "start_epoch = 1\n",
    "\n",
    "teacher_forcing_rate = 1\n",
    "write_log = False\n",
    "change_lr = False\n",
    "\n",
    "\n",
    "def predict(encoder, decoder, input_text, max_len=10):\n",
    "    with torch.no_grad():\n",
    "        input_code = text2int(word_index_fra, [input_text])\n",
    "        input_tensor = torch.tensor(input_code, dtype=torch.long).permute(1,0).to(device)\n",
    "        e_out, context_vector = encoder(input_tensor, encoder.initHidden(1))\n",
    "    #     print(context_vector)\n",
    "        bos_tensor = torch.tensor(word_index_eng['<bos>'], dtype=torch.long).view(1,1).to(device)\n",
    "        decoder_out, decoder_state, attn_weights = decoder(bos_tensor, context_vector, e_out)\n",
    "    #     print(decoder_out.sum())\n",
    "        pred_int = decoder_out.argmax().item()\n",
    "        input_tensor = decoder_out.argmax().view(1,1)\n",
    "    #     print(input_tensor)\n",
    "    #     print(pred_int)\n",
    "        res = []\n",
    "        count = 0\n",
    "        while pred_int!=word_index_eng['<eos>'] and count<max_len:\n",
    "            res.append(pred_int)\n",
    "            decoder_out, decoder_state, attn_weights = decoder(input_tensor, decoder_state, e_out)\n",
    "            pred_int = decoder_out.argmax().item()\n",
    "            input_tensor = decoder_out.argmax().view(1,1)\n",
    "            count += 1\n",
    "    return int2text(index_word_eng, [res])[0]\n",
    "\n",
    "def predict_with_atten(encoder, decoder, input_text, max_len=10):\n",
    "    with torch.no_grad():\n",
    "        atten_w = []\n",
    "        input_code = text2int(word_index_fra, [input_text])\n",
    "        input_tensor = torch.tensor(input_code, dtype=torch.long).permute(1,0).to(device)\n",
    "        e_out, context_vector = encoder(input_tensor, encoder.initHidden(1))\n",
    "    #     print(context_vector)\n",
    "        bos_tensor = torch.tensor(word_index_eng['<bos>'], dtype=torch.long).view(1,1).to(device)\n",
    "        decoder_out, decoder_state, attn_weights = decoder(bos_tensor, context_vector, e_out)\n",
    "\n",
    "        atten_w.append(attn_weights)\n",
    "    #     print(decoder_out.sum())\n",
    "        pred_int = decoder_out.argmax().item()\n",
    "        input_tensor = decoder_out.argmax().view(1,1)\n",
    "    #     print(input_tensor)\n",
    "    #     print(pred_int)\n",
    "        res = []\n",
    "        count = 0\n",
    "        while pred_int!=word_index_eng['<eos>'] and count<max_len:\n",
    "            res.append(pred_int)\n",
    "            decoder_out, decoder_state, attn_weights = decoder(input_tensor, decoder_state, e_out)\n",
    "\n",
    "            atten_w.append(attn_weights)\n",
    "            pred_int = decoder_out.argmax().item()\n",
    "            input_tensor = decoder_out.argmax().view(1,1)\n",
    "            count += 1\n",
    "        atten_w = torch.cat(atten_w, dim=0).cpu().numpy()\n",
    "    return int2text(index_word_eng, [res])[0], atten_w\n",
    "\n",
    "\n",
    "def evel_bleu(test_pair, encoder, decoder):\n",
    "    res = []\n",
    "    for i in range(test_pair.shape[0]):\n",
    "        pred = predict(encoder, decoder, test_pair.iloc[i, 1])\n",
    "        pred = process_text(pred)\n",
    "        res.append(BLEU(pred, test_pair.iloc[i, 0]))\n",
    "    return np.mean(res)\n",
    "\n",
    "\n",
    "def calc_acc(true, pred):\n",
    "    with torch.no_grad():\n",
    "        acc = torch.eq(true, pred).float().mean().item()\n",
    "    return acc\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    if epoch < 2:\n",
    "        lr = .005\n",
    "    elif epoch < 6:\n",
    "        lr = .002\n",
    "    elif epoch < 9:\n",
    "        lr = .001\n",
    "    elif epoch < 12:\n",
    "        lr = .0005\n",
    "    else:\n",
    "        lr = .0002\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "dataset = Datagen(text1, batch_size=batch_size, shuffle=False)\n",
    "num_iter_one_epoch = len(dataset)\n",
    "print(num_iter_one_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "encoder = EncoderRNN(num_word_fra, latent_dim).to(device)\n",
    "decoder = AttnDecoderRNN(latent_dim, num_word_eng, max_length=7).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.load_state_dict(torch.load('./model/encoder.mdl'))\n",
    "decoder.load_state_dict(torch.load('./model/decoder.mdl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "loss_fun = nn.NLLLoss()\n",
    "# loss_fun = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "if write_log:\n",
    "    writer = SummaryWriter(log_dir='logdir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2000/2000  loss: 0.157 - acc: 0.971\n",
      "loss: 0.371 - acc: 0.879 - train_bleu: 0.706 - test_bleu: 0.480\n"
     ]
    }
   ],
   "source": [
    "encoder_init_state = encoder.initHidden(batch_size)\n",
    "# decoder_init_state = decoder.initHidden(batch_size)\n",
    "for i in range(start_epoch, epochs+start_epoch):\n",
    "    print('Epoch {}/{}'.format(i, epochs+start_epoch-1))\n",
    "    dataset.shuffle_data()\n",
    "    if change_lr:\n",
    "        adjust_learning_rate(encoder_optimizer, i)\n",
    "        adjust_learning_rate(decoder_optimizer, i)\n",
    "        \n",
    "    epoch_acc = []\n",
    "    epoch_loss = []\n",
    "    \n",
    "    for j in range(0, num_iter_one_epoch):\n",
    "        x, y1, y2 = dataset[j]  # x, y1, y2 shape: (seq_len, batch_size)\n",
    "        x = x.to(device)\n",
    "        y1 = y1.to(device)\n",
    "        y2 = y2.to(device)\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        e_out, context_vector = encoder(x, encoder_init_state)\n",
    "        decoder_state = context_vector\n",
    "        decoder_out = []\n",
    "        decoder_input = y1[0].view(1,-1)\n",
    "        for k in range(y1.shape[0]):    \n",
    "            out, decoder_state, attn_weights = decoder(decoder_input, decoder_state, e_out)  # out shape: (batch_size, class)\n",
    "            try:\n",
    "                decoder_input = y1[k + 1].view(1, -1) if np.random.rand() < teacher_forcing_rate \\\n",
    "                        else out.argmax(dim=1).view(1, -1).detach()\n",
    "            except:\n",
    "                pass\n",
    "            decoder_out.append(out)\n",
    "        decoder_outputs = torch.stack(decoder_out)\n",
    "        decoder_outputs_int = torch.argmax(decoder_outputs, dim=2)\n",
    "        acc = calc_acc(y2.view(-1), decoder_outputs_int.view(-1))\n",
    "        loss = loss_fun(decoder_outputs.view(-1, num_word_eng), y2.view(-1))\n",
    "        print('{}/{}  loss: {:.3f} - acc: {:.3f}'.format(j+1, num_iter_one_epoch, loss.item(), acc), end='\\r')\n",
    "        \n",
    "        epoch_acc.append(acc)\n",
    "        epoch_loss.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        \n",
    "        if write_log:\n",
    "            writer.add_scalar('loss', loss, (i-1)*num_iter_one_epoch+j+1)\n",
    "            writer.add_scalar('acc', acc, (i-1)*num_iter_one_epoch+j+1)\n",
    "        \n",
    "    test_bleu = evel_bleu(text2, encoder, decoder)\n",
    "    train_bleu = evel_bleu(text1[:2000], encoder, decoder)\n",
    "    print('\\nloss: {:.3f} - acc: {:.3f} - train_bleu: {:.3f} - test_bleu: {:.3f}'\\\n",
    "          .format(np.mean(epoch_loss), np.mean(epoch_acc), train_bleu, test_bleu))\n",
    "    \n",
    "    if write_log:\n",
    "        writer.add_scalar('test_bleu', test_bleu, i*num_iter_one_epoch)\n",
    "        writer.add_scalar('train_bleu', train_bleu, i*num_iter_one_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), './model/encoder.mdl')\n",
    "torch.save(decoder.state_dict(), './model/decoder.mdl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Train self-attention as encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 256\n",
    "batch_size = 2\n",
    "learning_rate = .001\n",
    "epochs = 10\n",
    "start_epoch = 1\n",
    "\n",
    "teacher_forcing_rate = 1\n",
    "write_log = False\n",
    "change_lr = False\n",
    "\n",
    "\n",
    "def predict(encoder, decoder, input_text, max_len=10):\n",
    "    with torch.no_grad():\n",
    "        input_code = text2int(word_index_fra, [input_text])\n",
    "        input_tensor = torch.tensor(input_code, dtype=torch.long).permute(1,0).to(device)\n",
    "        _, context_vector, _ = encoder(input_tensor)\n",
    "    #     print(context_vector)\n",
    "        bos_tensor = torch.tensor(word_index_eng['<bos>'], dtype=torch.long).view(1,1).to(device)\n",
    "        decoder_out, decoder_state = decoder(bos_tensor, context_vector.unsqueeze(0))\n",
    "    #     print(decoder_out.sum())\n",
    "        pred_int = decoder_out.argmax().item()\n",
    "        input_tensor = decoder_out.argmax().view(1,1)\n",
    "    #     print(input_tensor)\n",
    "    #     print(pred_int)\n",
    "        res = []\n",
    "        count = 0\n",
    "        while pred_int!=word_index_eng['<eos>'] and count<max_len:\n",
    "            res.append(pred_int)\n",
    "            decoder_out, decoder_state = decoder(input_tensor, decoder_state)\n",
    "            pred_int = decoder_out.argmax().item()\n",
    "            input_tensor = decoder_out.argmax().view(1,1)\n",
    "            count += 1\n",
    "    return int2text(index_word_eng, [res])[0]\n",
    "\n",
    "\n",
    "def predict_with_self_atten(encoder, decoder, input_text, max_len=10):\n",
    "    with torch.no_grad():\n",
    "        input_code = text2int(word_index_fra, [input_text])\n",
    "        input_tensor = torch.tensor(input_code, dtype=torch.long).permute(1,0).to(device)\n",
    "        _, context_vector, sat_w = encoder(input_tensor)\n",
    "    #     print(context_vector)\n",
    "        bos_tensor = torch.tensor(word_index_eng['<bos>'], dtype=torch.long).view(1,1).to(device)\n",
    "        decoder_out, decoder_state = decoder(bos_tensor, context_vector.unsqueeze(0))\n",
    "    #     print(decoder_out.sum())\n",
    "        pred_int = decoder_out.argmax().item()\n",
    "        input_tensor = decoder_out.argmax().view(1,1)\n",
    "    #     print(input_tensor)\n",
    "    #     print(pred_int)\n",
    "        res = []\n",
    "        count = 0\n",
    "        while pred_int!=word_index_eng['<eos>'] and count<max_len:\n",
    "            res.append(pred_int)\n",
    "            decoder_out, decoder_state = decoder(input_tensor, decoder_state)\n",
    "            pred_int = decoder_out.argmax().item()\n",
    "            input_tensor = decoder_out.argmax().view(1,1)\n",
    "            count += 1\n",
    "    return int2text(index_word_eng, [res])[0], sat_w.squeeze(0).cpu().numpy()\n",
    "\n",
    "\n",
    "def evel_bleu(test_pair, encoder, decoder):\n",
    "    res = []\n",
    "    for i in range(test_pair.shape[0]):\n",
    "        pred = predict(encoder, decoder, test_pair.iloc[i, 1])\n",
    "        pred = process_text(pred)\n",
    "        res.append(BLEU(pred, test_pair.iloc[i, 0]))\n",
    "    return np.mean(res)\n",
    "\n",
    "\n",
    "def calc_acc(true, pred):\n",
    "    with torch.no_grad():\n",
    "        acc = torch.eq(true, pred).float().mean().item()\n",
    "    return acc\n",
    "    \n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    if epoch < 2:\n",
    "        lr = .002\n",
    "    elif epoch < 7:\n",
    "        lr = .001\n",
    "    elif epoch < 12:\n",
    "        lr = .0005\n",
    "    elif epoch < 16:\n",
    "        lr = .0002  # .0002\n",
    "    else:\n",
    "        lr = .0001  # .0001\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "sat_encoder = SelfAttenEncoder(num_word_fra, latent_dim=latent_dim).to(device)\n",
    "decoder = DecoderRNN(latent_dim, num_word_eng).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "dataset = Datagen(text1, batch_size=batch_size, shuffle=False)\n",
    "num_iter_one_epoch = len(dataset)\n",
    "print(num_iter_one_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_encoder_optimizer = optim.Adam(sat_encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "loss_fun = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5000/5000  loss: 0.386 - acc: 0.9009\n",
      "loss: 0.601 - acc: 0.846 - train_bleu: 0.646 - test_bleu: 0.464\n",
      "Epoch 2/10\n",
      "5000/5000  loss: 0.452 - acc: 0.786\n",
      "loss: 0.545 - acc: 0.854 - train_bleu: 0.640 - test_bleu: 0.462\n",
      "Epoch 3/10\n",
      "5000/5000  loss: 0.321 - acc: 0.900\n",
      "loss: 0.542 - acc: 0.856 - train_bleu: 0.667 - test_bleu: 0.491\n",
      "Epoch 4/10\n",
      "5000/5000  loss: 0.838 - acc: 0.8330\n",
      "loss: 0.535 - acc: 0.859 - train_bleu: 0.659 - test_bleu: 0.478\n",
      "Epoch 5/10\n",
      "5000/5000  loss: 0.063 - acc: 1.0009\n",
      "loss: 0.541 - acc: 0.860 - train_bleu: 0.661 - test_bleu: 0.479\n",
      "Epoch 6/10\n",
      "5000/5000  loss: 0.541 - acc: 0.900\n",
      "loss: 0.526 - acc: 0.860 - train_bleu: 0.650 - test_bleu: 0.471\n",
      "Epoch 7/10\n",
      "5000/5000  loss: 0.079 - acc: 0.929\n",
      "loss: 0.524 - acc: 0.864 - train_bleu: 0.669 - test_bleu: 0.489\n",
      "Epoch 8/10\n",
      "5000/5000  loss: 0.983 - acc: 0.786\n",
      "loss: 0.530 - acc: 0.863 - train_bleu: 0.664 - test_bleu: 0.484\n",
      "Epoch 9/10\n",
      "5000/5000  loss: 0.162 - acc: 0.917\n",
      "loss: 0.530 - acc: 0.862 - train_bleu: 0.675 - test_bleu: 0.474\n",
      "Epoch 10/10\n",
      "5000/5000  loss: 1.363 - acc: 0.786\n",
      "loss: 0.528 - acc: 0.863 - train_bleu: 0.669 - test_bleu: 0.487\n"
     ]
    }
   ],
   "source": [
    "if write_log:\n",
    "    writer = SummaryWriter(log_dir='logdir')\n",
    "    \n",
    "\n",
    "for i in range(start_epoch, epochs+start_epoch):\n",
    "    print('Epoch {}/{}'.format(i, epochs+start_epoch-1))\n",
    "    dataset.shuffle_data()\n",
    "    \n",
    "    if change_lr:\n",
    "        adjust_learning_rate(sat_encoder_optimizer, i)\n",
    "        adjust_learning_rate(decoder_optimizer, i)\n",
    "    \n",
    "    epoch_acc = []\n",
    "    epoch_loss = []\n",
    "    for j in range(0, num_iter_one_epoch):\n",
    "        x, y1, y2 = dataset[j]  # x, y1, y2 shape: (seq_len, batch_size)\n",
    "        x = x.to(device)\n",
    "        y1 = y1.to(device)\n",
    "        y2 = y2.to(device)\n",
    "        sat_encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        _, context_vector, _ = sat_encoder(x)\n",
    "        decoder_state = context_vector.unsqueeze(0)\n",
    "        decoder_out = []\n",
    "        decoder_input = y1[0].view(1,-1)\n",
    "        for k in range(y1.shape[0]):    \n",
    "            out, decoder_state = decoder(decoder_input, decoder_state)  # out shape: (batch_size, class)\n",
    "            try:\n",
    "                decoder_input = y1[k + 1].view(1, -1) if np.random.rand() < teacher_forcing_rate \\\n",
    "                        else out.argmax(dim=1).view(1, -1).detach()\n",
    "            except:\n",
    "                pass\n",
    "            decoder_out.append(out)\n",
    "        decoder_outputs = torch.stack(decoder_out)\n",
    "        decoder_outputs_int = torch.argmax(decoder_outputs, dim=2)\n",
    "        acc = calc_acc(y2.view(-1), decoder_outputs_int.view(-1))\n",
    "        loss = loss_fun(decoder_outputs.view(-1, num_word_eng), y2.view(-1))\n",
    "        print('{}/{}  loss: {:.3f} - acc: {:.3f}'.format(j+1, num_iter_one_epoch, loss.item(), acc), end='\\r')\n",
    "        \n",
    "        epoch_acc.append(acc)\n",
    "        epoch_loss.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        sat_encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        \n",
    "        if write_log:\n",
    "            writer.add_scalar('loss', loss, (i-1)*num_iter_one_epoch+j+1)\n",
    "            writer.add_scalar('acc', acc, (i-1)*num_iter_one_epoch+j+1)\n",
    "        \n",
    "    test_bleu = evel_bleu(text2, sat_encoder, decoder)\n",
    "    train_bleu = evel_bleu(text1[:2000], sat_encoder, decoder)\n",
    "    print('\\nloss: {:.3f} - acc: {:.3f} - train_bleu: {:.3f} - test_bleu: {:.3f}'\\\n",
    "          .format(np.mean(epoch_loss), np.mean(epoch_acc), train_bleu, test_bleu))\n",
    "    \n",
    "    if write_log:\n",
    "        writer.add_scalar('test_bleu', test_bleu, i*num_iter_one_epoch)\n",
    "        writer.add_scalar('train_bleu', train_bleu, i*num_iter_one_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(sat_encoder.state_dict(), './model/sat_encoder.mdl')\n",
    "torch.save(decoder.state_dict(), './model/decoder.mdl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train self-attention as encoder and decoder\n",
    "\n",
    "- 好像不 work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 256\n",
    "batch_size = 5\n",
    "learning_rate = .002\n",
    "epochs = 2\n",
    "start_epoch = 1\n",
    "max_len = 9\n",
    "\n",
    "# teacher_forcing_rate = 1\n",
    "write_log = False\n",
    "change_lr = False\n",
    "\n",
    "\n",
    "def predict(encoder, decoder, input_text):\n",
    "    with torch.no_grad():\n",
    "        input_code = text2int(word_index_fra, [input_text])\n",
    "        input_tensor = torch.tensor(input_code, dtype=torch.long).permute(1,0).to(device)\n",
    "        encoder_outputs,_ , _ = encoder(input_tensor)\n",
    "        decoder_ouputs, _ = decoder(encoder_outputs)\n",
    "        pred_int = decoder_outputs.argmax(dim=2).permute(1,0).cpu().numpy().tolist()\n",
    "        pred_text = int2text(index_word_eng, pred_int)[0]\n",
    "    return pred_text\n",
    "\n",
    "\n",
    "def evel_bleu(test_pair, encoder, decoder):\n",
    "    res = []\n",
    "    for i in range(test_pair.shape[0]):\n",
    "        pred = predict(encoder, decoder, test_pair.iloc[i, 1])\n",
    "        pred = process_text(pred)\n",
    "        res.append(BLEU(pred, test_pair.iloc[i, 0]))\n",
    "    return np.mean(res)\n",
    "\n",
    "\n",
    "def calc_acc(true, pred):\n",
    "    with torch.no_grad():\n",
    "        acc = torch.eq(true, pred).float().mean().item()\n",
    "    return acc\n",
    "    \n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    if epoch < 2:\n",
    "        lr = .002\n",
    "    elif epoch < 7:\n",
    "        lr = .001\n",
    "    elif epoch < 12:\n",
    "        lr = .0005\n",
    "    elif epoch < 16:\n",
    "        lr = .0002  # .0002\n",
    "    else:\n",
    "        lr = .0001  # .0001\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "dataset = Datagen(text1, batch_size=batch_size, shuffle=False)\n",
    "num_iter_one_epoch = len(dataset)\n",
    "print(num_iter_one_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "sat_encoder = SelfAttenEncoder(num_word_fra, latent_dim=latent_dim).to(device)\n",
    "sat_decoder = SelfAttenDecoder(num_word_eng, latent_dim, max_len=9).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_encoder_optimizer = optim.Adam(sat_encoder.parameters(), lr=learning_rate)\n",
    "sat_decoder_optimizer = optim.Adam(sat_decoder.parameters(), lr=learning_rate)\n",
    "loss_fun = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2000/2000  loss: 3.426 - acc: 0.2679\n",
      "loss: 3.430 - acc: 0.322 - train_bleu: 0.000 - test_bleu: 0.000\n",
      "Epoch 2/2\n",
      "2000/2000  loss: 3.098 - acc: 0.3787\n",
      "loss: 3.419 - acc: 0.323 - train_bleu: 0.000 - test_bleu: 0.000\n"
     ]
    }
   ],
   "source": [
    "if write_log:\n",
    "    writer = SummaryWriter(log_dir='logdir')\n",
    "    \n",
    "\n",
    "for i in range(start_epoch, epochs+start_epoch):\n",
    "    print('Epoch {}/{}'.format(i, epochs+start_epoch-1))\n",
    "    dataset.shuffle_data()\n",
    "    \n",
    "    if change_lr:\n",
    "        adjust_learning_rate(sat_encoder_optimizer, i)\n",
    "        adjust_learning_rate(sat_decoder_optimizer, i)\n",
    "    \n",
    "    epoch_acc = []\n",
    "    epoch_loss = []\n",
    "    for j in range(0, num_iter_one_epoch):\n",
    "        x, _, y2 = dataset[j]  # x, y1, y2 shape: (seq_len, batch_size)\n",
    "        x = x.to(device)\n",
    "#         y1 = y1.to(device)\n",
    "        valid_len = y2.shape[0]\n",
    "        y = torch.zeros(max_len, batch_size, dtype=torch.long)\n",
    "        for i in range(min(max_len, valid_len)): y[i] = y2[i]\n",
    "        y = y.to(device)\n",
    "        sat_encoder_optimizer.zero_grad()\n",
    "        sat_decoder_optimizer.zero_grad()\n",
    "        encoder_outputs, _, _ = sat_encoder(x)\n",
    "#         decoder_state = context_vector.unsqueeze(0)\n",
    "#         decoder_out = []\n",
    "#         decoder_input = y1[0].view(1,-1)\n",
    "#         for k in range(y1.shape[0]):    \n",
    "#             out, decoder_state = decoder(decoder_input, decoder_state)  # out shape: (batch_size, class)\n",
    "#             try:\n",
    "#                 decoder_input = y1[k + 1].view(1, -1) if np.random.rand() < teacher_forcing_rate \\\n",
    "#                         else out.argmax(dim=1).view(1, -1).detach()\n",
    "#             except:\n",
    "#                 pass\n",
    "#             decoder_out.append(out)\n",
    "#         decoder_outputs = torch.stack(decoder_out)\n",
    "        decoder_outputs, _ = sat_decoder(encoder_outputs)\n",
    "        decoder_outputs_int = torch.argmax(decoder_outputs, dim=2)\n",
    "        acc = calc_acc(y.view(-1), decoder_outputs_int.view(-1))\n",
    "        loss = loss_fun(decoder_outputs.view(-1, num_word_eng), y.view(-1))\n",
    "        print('{}/{}  loss: {:.3f} - acc: {:.3f}'.format(j+1, num_iter_one_epoch, loss.item(), acc), end='\\r')\n",
    "        \n",
    "        epoch_acc.append(acc)\n",
    "        epoch_loss.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        sat_encoder_optimizer.step()\n",
    "        sat_decoder_optimizer.step()\n",
    "        \n",
    "        if write_log:\n",
    "            writer.add_scalar('loss', loss, (i-1)*num_iter_one_epoch+j+1)\n",
    "            writer.add_scalar('acc', acc, (i-1)*num_iter_one_epoch+j+1)\n",
    "        \n",
    "    test_bleu = evel_bleu(text2, sat_encoder, sat_decoder)\n",
    "    train_bleu = evel_bleu(text1[:2000], sat_encoder, sat_decoder)\n",
    "    print('\\nloss: {:.3f} - acc: {:.3f} - train_bleu: {:.3f} - test_bleu: {:.3f}'\\\n",
    "          .format(np.mean(epoch_loss), np.mean(epoch_acc), train_bleu, test_bleu))\n",
    "    \n",
    "    if write_log:\n",
    "        writer.add_scalar('test_bleu', test_bleu, i*num_iter_one_epoch)\n",
    "        writer.add_scalar('train_bleu', train_bleu, i*num_iter_one_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47529118415183724"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evel_bleu(text2, encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show attention score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Je suis fort contrarié.\n",
      "= I'm very upset.\n",
      "< i'm very upset.\n",
      "(7, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_atten_weights(atten_w, in_text, out_text):\n",
    "    tokenizer = CountVectorizer(token_pattern=r\"\\b\\w+\\b|!|\\?|\\'|\\.\").build_tokenizer()\n",
    "    plt.figure()\n",
    "    plt.matshow(atten_w)\n",
    "    in_text_list = tokenizer(in_text)\n",
    "    out_text_list = tokenizer(out_text+' <eos>')\n",
    "    plt.gca().set_xticks(range(atten_w.shape[1]))\n",
    "    plt.gca().set_yticks(range(atten_w.shape[0]))\n",
    "    plt.gca().set_xticklabels(in_text_list, rotation=90)\n",
    "    plt.gca().set_yticklabels(out_text_list)\n",
    "\n",
    "ind = np.random.choice(text1.shape[0])\n",
    "input_text = text1.iloc[ind, 1]\n",
    "target_text = text1.iloc[ind, 0]\n",
    "pred_text, atten_w = predict_with_atten(encoder, decoder, input_text)\n",
    "pred_text = process_text(pred_text)\n",
    "print('>', input_text)\n",
    "print('=', target_text)\n",
    "print('<', pred_text)\n",
    "\n",
    "print(atten_w.shape)\n",
    "show_atten_weights(atten_w, input_text, pred_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.9128802e-04, 1.5847726e-02, 6.6546094e-01, 1.7151047e-01,\n",
       "       5.9876207e-02, 6.8145514e-02, 1.8767871e-02], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atten_w[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show self-attention score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> J'en ai assez entendu.\n",
      "= I've had enough.\n",
      "< i had enough.\n",
      "(7, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_self_atten_weights(input_text, sat_w):\n",
    "    tokenizer = CountVectorizer(token_pattern=r\"\\b\\w+\\b|!|\\?|\\'|\\.\").build_tokenizer()\n",
    "    plt.figure()\n",
    "    plt.matshow(sat_w)\n",
    "    text_list = tokenizer(input_text)\n",
    "    plt.gca().set_xticks(range(len(text_list)))\n",
    "    plt.gca().set_yticks(range(len(text_list)))\n",
    "    plt.gca().set_xticklabels(text_list, rotation=90)\n",
    "    plt.gca().set_yticklabels(text_list)\n",
    "\n",
    "ind = np.random.choice(text1.shape[0])\n",
    "input_text = text1.iloc[ind, 1]\n",
    "target_text = text1.iloc[ind, 0]\n",
    "pred_text, sat_w = predict_with_self_atten(sat_encoder, decoder, input_text)\n",
    "pred_text = process_text(pred_text)\n",
    "print('>', input_text)\n",
    "print('=', target_text)\n",
    "print('<', pred_text)\n",
    "\n",
    "print(sat_w.shape)\n",
    "show_self_atten_weights(input_text, sat_w)\n",
    "sat_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Est-ce que j'avais tort ?\n",
      "= Was I wrong?\n",
      "< <null> <null> <null> <null> <null> <null> <null> <null> <null>\n"
     ]
    }
   ],
   "source": [
    "ind = np.random.choice(text1.shape[0])\n",
    "input_text = text1.iloc[ind, 1]\n",
    "target_text = text1.iloc[ind, 0]\n",
    "pred_text = process_text(predict(sat_encoder, sat_decoder, input_text))\n",
    "print('>', input_text)\n",
    "print('=', target_text)\n",
    "print('<', pred_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "439"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index_eng['gloat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> M'en parle pas.\n",
      "= Don't tell me.\n",
      "< don't attack me.\n"
     ]
    }
   ],
   "source": [
    "ind = np.random.choice(text2.shape[0])\n",
    "input_text = text2.iloc[ind, 1]\n",
    "target_text = text2.iloc[ind, 0]\n",
    "pred_text = process_text(predict(encoder, decoder, input_text))\n",
    "print('>', input_text)\n",
    "print('=', target_text)\n",
    "print('<', pred_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLEU(process_text(\"tom is hurt Bad .\"), \"Tom is hurt bad.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
